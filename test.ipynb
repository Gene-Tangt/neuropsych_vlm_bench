{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd33051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_specs/mid/borb_overlapped_letters_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting model responses: 100%|██████████| 36/36 [00:26<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json \n",
    "from runner import OpenAIModelRunner\n",
    "from loaders import TaskLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Paths = \"test_specs/test_list.json\"\n",
    "\n",
    "all_task_paths = []\n",
    "with open(Paths, 'r') as file:\n",
    "    for stage in json.load(file):\n",
    "        all_task_paths.extend(stage['task_paths'])\n",
    "\n",
    "api = \"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\"\n",
    "\n",
    "\n",
    "for i in range(len(all_task_paths))[5:6]:\n",
    "    print(all_task_paths[i])\n",
    "    loader = TaskLoader(all_task_paths[i])\n",
    "    runner = OpenAIModelRunner(api_key=api, model_name=\"gpt-4o\")\n",
    "    data = runner.generate_response(loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9b4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Model answer: Counter({'e': 1, 'a': 1}), Answer key: Counter({'e': 1, 'j': 1, 'a': 1}), pts: 0\n",
      "Model answer: Counter({'r': 1, 'x': 1}), Answer key: Counter({'y': 1, 'r': 1, 'x': 1}), pts: 0\n",
      "Model answer: Counter({'c': 1, 'f': 1}), Answer key: Counter({'g': 1, 'f': 1, 't': 1}), pts: 0\n",
      "Model answer: Counter({'e': 1, 'f': 1}), Answer key: Counter({'h': 1, 'e': 1, 'c': 1}), pts: 0\n",
      "Model answer: Counter({'s': 1, 'e': 1, 'f': 1}), Answer key: Counter({'f': 1, 'h': 1, 's': 1}), pts: 0\n",
      "Model answer: Counter({'s': 1, 'e': 1, 'z': 1}), Answer key: Counter({'l': 1, 's': 1, 'z': 1}), pts: 0\n",
      "Model answer: Counter({'r': 1, 'f': 1, 'z': 1}), Answer key: Counter({'i': 1, 'r': 1, 'z': 1}), pts: 0\n",
      "Model answer: Counter({'a': 1, 'i': 1, 'v': 1}), Answer key: Counter({'w': 1, 'p': 1, 'a': 1}), pts: 0\n",
      "Model answer: Counter({'l': 1, 'g': 1, 'c': 1, 'n': 1, 'v': 1, 'm': 1}), Answer key: Counter({'c': 1, 'm': 1, 'l': 1}), pts: 0\n",
      "Model answer: Counter({'u': 1, 'h': 1, 'f': 1}), Answer key: Counter({'h': 1, 'u': 1, 'e': 1}), pts: 0\n",
      "Model answer: Counter({'l': 1, 'v': 1}), Answer key: Counter({'v': 1, 'd': 1, 'l': 1}), pts: 0\n",
      "Model answer: Counter({'n': 1, 'y': 1}), Answer key: Counter({'n': 1, 'b': 1, 'a': 1}), pts: 0\n",
      "Model answer: Counter({'m': 1, 'v': 1, 'u': 1}), Answer key: Counter({'v': 1, 'm': 1, 'u': 1}), pts: 1\n",
      "Model answer: Counter({'u': 1, 'v': 1, 'w': 1}), Answer key: Counter({'j': 1, 'u': 1, 'w': 1}), pts: 0\n",
      "Model answer: Counter({'u': 1, 'k': 1, 'b': 1}), Answer key: Counter({'k': 1, 'u': 1, 'b': 1}), pts: 1\n",
      "Model answer: Counter({'s': 1, 'w': 1, 'f': 1}), Answer key: Counter({'w': 1, 's': 1, 'u': 1}), pts: 0\n",
      "Model answer: Counter({'o': 1, 'm': 1, 'n': 1}), Answer key: Counter({'o': 1, 'e': 1, 'm': 1}), pts: 0\n",
      "Model answer: Counter({'n': 1, 'o': 1, 'v': 1}), Answer key: Counter({'n': 1, 'q': 1, 'v': 1}), pts: 0\n",
      "Model answer: Counter({'c': 1, 'm': 1}), Answer key: Counter({'f': 1, 'm': 1, 'o': 1}), pts: 0\n",
      "Model answer: Counter({'s': 1, 'f': 1, 'y': 1}), Answer key: Counter({'s': 1, 'x': 1, 'y': 1}), pts: 0\n",
      "Model answer: Counter({'h': 1, 'n': 1, 'm': 1}), Answer key: Counter({'n': 1, 'h': 1, 'm': 1}), pts: 1\n",
      "Model answer: Counter({'s': 1, 'a': 1, 'f': 1, 'e': 1}), Answer key: Counter({'s': 1, 't': 1, 'e': 1}), pts: 0\n",
      "Model answer: Counter({'v': 1, 'k': 1, 'u': 1}), Answer key: Counter({'v': 1, 'k': 1, 'u': 1}), pts: 1\n",
      "Model answer: Counter({'k': 1, 'f': 1}), Answer key: Counter({'e': 1, 'h': 1, 'k': 1}), pts: 0\n",
      "Model answer: Counter({'f': 1, 'r': 1}), Answer key: Counter({'f': 1, 'b': 1, 'n': 1}), pts: 0\n",
      "Model answer: Counter({'h': 1, 's': 1, 'p': 1}), Answer key: Counter({'d': 1, 'h': 1, 's': 1}), pts: 0\n",
      "Model answer: Counter({'s': 1, 'a': 1, 'm': 1}), Answer key: Counter({'s': 1, 'f': 1, 'm': 1}), pts: 0\n",
      "Model answer: Counter({'v': 1, 'g': 1}), Answer key: Counter({'v': 1, 's': 1, 'g': 1}), pts: 0\n",
      "Model answer: Counter({'f': 1, 'w': 1}), Answer key: Counter({'d': 1, 'w': 1, 'f': 1}), pts: 0\n",
      "Model answer: Counter({'e': 1, 'x': 1}), Answer key: Counter({'b': 1, 'x': 1, 'z': 1}), pts: 0\n",
      "Model answer: Counter({'z': 1, 'f': 1}), Answer key: Counter({'l': 1, 'j': 1, 'z': 1}), pts: 0\n",
      "Model answer: Counter({'l': 1, 'o': 1, 'v': 1, 'e': 1}), Answer key: Counter({'j': 1, 'o': 1, 'k': 1}), pts: 0\n",
      "Model answer: Counter({'n': 1, 'y': 1}), Answer key: Counter({'m': 1, 'y': 1, 's': 1}), pts: 0\n",
      "Model answer: Counter({'k': 1, 'w': 1}), Answer key: Counter({'w': 1, 'i': 1, 'z': 1}), pts: 0\n",
      "Model answer: Counter({'o': 1, 'm': 1}), Answer key: Counter({'m': 1, 'q': 1, 'o': 1}), pts: 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from evaluator import Evaluator\n",
    "\n",
    "\n",
    "evaluator = Evaluator()\n",
    "evaluator.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7afe937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{EA}\n",
      "{RX}\n",
      "{CF}\n",
      "{EF}\n",
      "{SEF}\n",
      "{SEZ}\n",
      "{RFZ}\n",
      "{AIV}\n",
      "{LGCNVM}\n",
      "{UHF}\n",
      "{LV}\n",
      "{NY}\n",
      "{MVU}\n",
      "{UVW}\n",
      "{UKB}\n",
      "{SWF}\n",
      "{OMN}\n",
      "{NOV}\n",
      "{CM}\n",
      "{SFY}\n",
      "{HNM}\n",
      "{SAFE}\n",
      "{VKU}\n",
      "{KF}\n",
      "{FR}\n",
      "{HSP}\n",
      "{SAM}\n",
      "I'm unable to help with identifying or recognizing specific symbols or letters in the image.\n",
      "{VG}\n",
      "{FW}\n",
      "{EX}\n",
      "{Zf}\n",
      "{LOVE}\n",
      "{NY}\n",
      "{KW}\n",
      "{OM}\n"
     ]
    }
   ],
   "source": [
    "for trial in data[1]:\n",
    "    print(trial['model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0dcb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>task_type</th>\n",
       "      <th>stage</th>\n",
       "      <th>process</th>\n",
       "      <th>num_trials</th>\n",
       "      <th>raw_score</th>\n",
       "      <th>percent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>borb_overlapped_letters</td>\n",
       "      <td>naming</td>\n",
       "      <td>mid</td>\n",
       "      <td>occlusion_and_overlap</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      task task_type stage                process  num_trials  \\\n",
       "0  borb_overlapped_letters    naming   mid  occlusion_and_overlap          36   \n",
       "\n",
       "   raw_score  percent_score  \n",
       "0          4       0.111111  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = ['abc']\n",
    "b = {'cba'}\n",
    "\n",
    "Counter(a) == Counter(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
